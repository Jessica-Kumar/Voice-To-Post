import random
from typing import Dict, Any

def calculate_safety_score(generated_post: str, context_distance: float) -> Dict[str, Any]:
    """
    Implements the Safety Gatekeeper scoring logic.
    Formula: C = 0.3(AI Confidence) + 0.3(Retrieval Relevance) + 0.3(Safety Score) + 0.1(Engagement Potential)
    
    Args:
        generated_post (str): The post text generated by the AI.
        context_distance (float): The distance metric from FAISS search (lower distance = higher relevance, typically).
                                  If no context, this should be handled appropriately.
                                  
    Returns:
        Dict: A dictionary containing the final score 'C' and a breakdown of sub-scores.
    """
    
    # Mocking Semantic Scores
    # In a production environment, you might run another small LLM call or text moderation API to get these values
    
    # 1. AI Confidence [0.0 - 1.0]
    # Mocking based on length/structure properties, or returning a fixed high confidence for now.
    ai_confidence = 0.85 + (random.uniform(-0.1, 0.1)) 
    
    # 2. Retrieval Relevance [0.0 - 1.0]
    # In FAISS L2, distance is >= 0. Lower is better. 
    # Let's map L2 distance [0, max] -> Relevance [1, 0]. 
    # E.g. distance 0 -> 1.0 relevance. distance 2.0 -> 0.0 relevance.
    max_d = 2.0
    if context_distance == -1.0: # Our custom flag for "no context"
        retrieval_relevance = 0.5 # Neutral fallback
    else:
        # Clamp between 0 and 1
        retrieval_relevance = max(0.0, 1.0 - (context_distance / max_d))
    
    # 3. Safety Score [0.0 - 1.0]
    # Placeholder for moderation API. 
    # Check for simple forbidden terms for demo purposes:
    forbidden_terms = ["spam", "hate", "violence", "scam"]
    safety_score = 1.0
    for term in forbidden_terms:
        if term in generated_post.lower():
            safety_score = 0.1 # Severe penalty
            break
            
    # 4. Engagement Potential [0.0 - 1.0]
    # E.g. presence of hashtags/emojis might bump engagement score
    engagement_potential = 0.6
    if "#" in generated_post:
        engagement_potential += 0.2
    if any(char in generated_post for char in ["!", "?", "ðŸš€", "ðŸ’¡", "ðŸ”¥"]):
        engagement_potential += 0.1
    engagement_potential = min(1.0, engagement_potential) # Cap at 1.0
    
    
    # Final Formula Calculation
    c_score = (0.3 * ai_confidence) + \
              (0.3 * retrieval_relevance) + \
              (0.3 * safety_score) + \
              (0.1 * engagement_potential)
              
    return {
        "final_score": round(c_score, 3),
        "breakdown": {
            "ai_confidence": round(ai_confidence, 3),
            "retrieval_relevance": round(retrieval_relevance, 3),
            "safety_score": round(safety_score, 3),
            "engagement_potential": round(engagement_potential, 3)
        }
    }
